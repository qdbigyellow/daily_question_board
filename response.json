{
  "timestamp": "2025-12-27 09:19:37 UTC",
  "response": "Here are three multiple-choice questions tailored to your specifications:\n\n---\n\n### 1. AWS Architect (Intermediate Level)\n\n**Question:**\nA company is deploying a critical web application on AWS that requires high availability and automatic scaling for peak loads, while also maintaining cost efficiency. The application tier runs on EC2 instances, and the data tier uses Amazon RDS for PostgreSQL. Which architectural approach best meets these requirements for both the application and database tiers?\n\n**Answer Options:**\nA. Deploy EC2 instances in a single Availability Zone (AZ) within an Auto Scaling Group, behind an Application Load Balancer (ALB). Deploy the RDS PostgreSQL instance as a Single-AZ deployment.\nB. Deploy EC2 instances across multiple AZs within an Auto Scaling Group, behind an ALB. Deploy the RDS PostgreSQL instance as a Single-AZ deployment.\nC. Deploy EC2 instances across multiple AZs within an Auto Scaling Group, behind an ALB. Deploy the RDS PostgreSQL instance as a Multi-AZ deployment.\nD. Manually provision two EC2 instances in separate AZs behind an ALB. Deploy the RDS PostgreSQL instance with read replicas in different AZs for high availability.\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **C is correct:** This option provides high availability and scalability for both the application and database tiers.\n    *   **Multi-AZ Auto Scaling Group with ALB for EC2:** Ensures application instances are distributed across multiple Availability Zones, protecting against AZ-wide failures. The Auto Scaling Group handles automatic scaling based on load and replaces unhealthy instances. The ALB distributes traffic and provides health checks.\n    *   **Multi-AZ RDS deployment:** Automatically provisions a synchronous standby replica in a different AZ. In case of a primary database instance failure or AZ outage, Amazon RDS automatically fails over to the standby, minimizing downtime and data loss. This also includes automated backups and patching, contributing to resilience.\n*   **A is incorrect:** A single-AZ Auto Scaling Group provides scaling and self-healing *within that AZ*, but not protection against an entire AZ failure. A Single-AZ RDS deployment is a single point of failure for the database.\n*   **B is incorrect:** While the application tier is highly available with a Multi-AZ ASG, the Single-AZ RDS deployment remains a single point of failure for the database, violating the requirement for high availability for *both* tiers.\n*   **D is incorrect:** Manually provisioning EC2 instances lacks the automatic scaling and self-healing capabilities of an Auto Scaling Group, making it less resilient and less cost-efficient for variable loads. RDS Read Replicas are primarily for scaling read traffic and offloading the primary database, not for automatic failover of the primary instance (which Multi-AZ RDS handles). While read replicas can be promoted, it's typically a manual or semi-manual process, not equivalent to the automatic failover of a Multi-AZ primary.\n\n---\n\n### 2. Terraform Script (Intermediate Level)\n\n**Question:**\nYou are writing a Terraform configuration to provision an AWS RDS instance. The database master password needs to be set securely, should not appear in plain text in logs or state files (if possible), and should be refreshable if rotated outside Terraform without forcing a replacement of the entire RDS instance. Which combination of Terraform features best addresses these requirements?\n\n**Answer Options:**\nA. Define a `variable` with `type = string` and directly assign the password in `terraform.tfvars`. Use `lifecycle { ignore_changes = [master_password] }` for the `aws_db_instance` resource.\nB. Define a `variable` with `type = string` and `sensitive = true`. Retrieve the password from a secure source like AWS Secrets Manager using a `data` source, and use `lifecycle { ignore_changes = [password] }` for the `aws_db_instance` resource.\nC. Define a `variable` with `type = string` and `sensitive = true`. Pass the password via the `TF_VAR_db_password` environment variable. Do not use `ignore_changes`.\nD. Hardcode the password directly in the `aws_db_instance` resource block. Use a `random_password` resource to generate a new password for each `terraform apply`.\n\n**Correct Answer:** B\n\n**Explanation:**\n*   **B is correct:**\n    *   `sensitive = true` on the variable ensures the password is redacted in `terraform plan` and `terraform apply` output, enhancing security by preventing accidental exposure in logs.\n    *   Using a `data` source (e.g., `aws_secretsmanager_secret_version`) is the industry best practice for securely fetching secrets at runtime without storing them in plain text in Terraform files or state. This keeps the secret out of version control and Terraform state files directly.\n    *   `lifecycle { ignore_changes = [password] }` (or `master_password`, depending on the specific argument name) is crucial. If the password is rotated externally (e.g., by an application or a separate security process), Terraform would detect a drift. Without `ignore_changes`, Terraform would attempt to apply its known state, potentially changing the password back or even forcing a replacement of the entire RDS instance, which is undesirable. This setting tells Terraform to ignore changes to this specific attribute after initial creation.\n*   **A is incorrect:** Storing the password directly in `terraform.tfvars` or any `.tf` file is insecure, as it resides in plain text in your code repository and potentially in state files. Even with `ignore_changes`, the initial exposure is a major vulnerability.\n*   **C is incorrect:** While `sensitive = true` and passing via environment variables are good practices for input and obscuring plan output, *not* using `ignore_changes` means that if the password is changed externally, Terraform will detect the drift and attempt to revert it or replace the resource on the next `apply`, violating the \"refreshable if rotated outside Terraform without forcing a replacement\" requirement.\n*   **D is incorrect:** Hardcoding passwords is a major security vulnerability. Using `random_password` would generate a *new* password on nearly every `terraform apply` (unless carefully managed with `keepers`), which is not suitable for a stable database password and would likely disrupt the application connection.\n\n---\n\n### 3. Python Programming (Advanced Level)\n\n**Question:**\nConsider the following Python code snippet:\n\n```python\ndef process_data_stream():\n    total = 0\n    while True:\n        data = yield total\n        if data is None:\n            break\n        try:\n            num = int(data)\n            total += num\n        except ValueError:\n            pass # Ignore non-integer data\n```\nIf you interact with this generator as follows:\n```python\ngen = process_data_stream()\nprint(next(gen)) # Initial prime\nprint(gen.send(\"10\"))\nprint(gen.send(\"hello\"))\nprint(gen.send(\"20\"))\nprint(gen.send(None))\n```\nWhat will be the output of the `print` statements?\n\n**Answer Options:**\nA.\n```\n0\n10\n10\n30\n<A StopIteration exception is raised by the last print statement>\n```\nB.\n```\n0\n10\n10\n30\n0\n```\nC.\n```\n0\n10\n30\n30\n<A StopIteration exception is raised by the last print statement>\n```\nD.\n```\n0\n10\n10\n30\nNone\n```\n\n**Correct Answer:** A\n\n**Explanation:**\n*   **A is correct:**\n    1.  `gen = process_data_stream()`: Creates the generator object.\n    2.  `print(next(gen))`: This primes the generator. Execution starts, `total` is initialized to `0`. The `yield total` statement is encountered. The generator pauses, and the value `0` is returned to `next()`. `print` outputs `0`. The `data` variable inside the generator is implicitly `None` (as if `gen.send(None)` was called to start it).\n    3.  `print(gen.send(\"10\"))`: The generator resumes from `data = yield total`. The value `\"10\"` is sent to `data`. It's not `None`. `int(\"10\")` is `10`. `total` becomes `0 + 10 = 10`. The generator yields `total` (which is `10`). `print` outputs `10`.\n    4.  `print(gen.send(\"hello\"))`: The generator resumes. The value `\"hello\"` is sent to `data`. It's not `None`. `int(\"hello\")` raises a `ValueError`, which is caught by the `try-except` block, and `pass` means no action is taken. `total` remains `10`. The generator yields `total` (which is `10`). `print` outputs `10`.\n    5.  `print(gen.send(\"20\"))`: The generator resumes. The value `\"20\"` is sent to `data`. It's not `None`. `int(\"20\")` is `20`. `total` becomes `10 + 20 = 30`. The generator yields `total` (which is `30`). `print` outputs `30`.\n    6.  `print(gen.send(None))`: The generator resumes. The value `None` is sent to `data`. The `if data is None:` condition is met, and `break` exits the `while True` loop. Since the generator function has finished executing, a `StopIteration` exception is raised by the `send()` call to signal that the generator is exhausted. The `print` statement cannot complete successfully with a value.\n*   **B is incorrect:** The last call to `send(None)` causes the generator to terminate and raise `StopIteration`; it does not yield `0` again.\n*   **C is incorrect:** The processing of `\"hello\"` is incorrect. A `ValueError` is caught and ignored, so `total` does not change from `10` when `\"hello\"` is processed.\n*   **D is incorrect:** The `send(None)` call leads to `StopIteration`, not a `None` value being yielded or printed. `None` is the *input* to the generator via `send(None)`, not its output."
}

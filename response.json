{
  "timestamp": "2025-12-05 09:21:18 UTC",
  "response": "Here are three multiple-choice questions (MCQs) designed to meet your specifications:\n\n---\n\n### **1. AWS Architect (Intermediate Level)**\n\n**Question:** An e-commerce platform experiences unpredictable traffic spikes and requires a highly available, fault-tolerant, and scalable database solution for its core transactional data (user orders, product inventory). The database must ensure data durability, support ACID transactions, and minimize operational overhead. Which AWS database architecture best meets these requirements?\n\n**Answer Options:**\nA. A single Amazon EC2 instance running a self-managed MySQL database.\nB. An Amazon RDS for PostgreSQL instance configured as a Multi-AZ deployment.\nC. An Amazon DynamoDB table with on-demand capacity mode and global tables enabled.\nD. A cluster of EC2 instances running Apache Cassandra across multiple Availability Zones.\n\n**Correct Answer:** B\n\n**Explanation:**\n*   **A. A single Amazon EC2 instance running a self-managed MySQL database:** This option offers no high availability, poor fault tolerance (single point of failure), and requires significant operational overhead for patching, backups, and scaling. It does not meet the requirements for high availability and minimal operational overhead.\n*   **B. An Amazon RDS for PostgreSQL instance configured as a Multi-AZ deployment:** This is the most suitable option.\n    *   **High Availability & Fault Tolerance:** Multi-AZ automatically provisions and maintains a synchronous standby replica in a different Availability Zone, providing automatic failover in case of an AZ outage or primary instance failure.\n    *   **Scalability:** RDS instances can be scaled vertically (instance size) and read replicas can be added for read-heavy workloads.\n    *   **Data Durability & ACID:** PostgreSQL is a relational database that inherently supports ACID transactions and RDS provides automatic backups and point-in-time recovery.\n    *   **Minimal Operational Overhead:** RDS is a fully managed service, reducing the burden of database administration tasks like patching, backups, and hardware provisioning.\n*   **C. An Amazon DynamoDB table with on-demand capacity mode and global tables enabled:** DynamoDB is a NoSQL database. While highly scalable, highly available, and low operational overhead, it is a key-value and document database and does not inherently enforce ACID transactions in the same way a relational database does for complex transactional data (e.g., across multiple tables in a single transaction). It's generally not the first choice for \"core transactional data\" that explicitly requires ACID properties if a relational model is suitable.\n*   **D. A cluster of EC2 instances running Apache Cassandra across multiple Availability Zones:** While Cassandra is highly scalable and fault-tolerant, deploying and managing it on EC2 instances (self-managed) incurs very high operational overhead, including cluster setup, monitoring, scaling, backups, and recovery. This contradicts the requirement to \"minimize operational overhead.\"\n\n---\n\n### **2. Terraform Script (Intermediate Level)**\n\n**Question:** You need to provision several S3 buckets, each with a unique name and different versioning requirements (either enabled or disabled). The configuration for these buckets is provided as a map variable `bucket_configs`, where keys are bucket names and values are objects containing a `versioning_enabled` boolean.\n\n```terraform\nvariable \"bucket_configs\" {\n  description = \"Map of S3 bucket configurations.\"\n  type = map(object({\n    versioning_enabled = bool\n  }))\n  default = {\n    \"app-logs-prod\" = {\n      versioning_enabled = true\n    },\n    \"data-archive-dev\" = {\n      versioning_enabled = false\n    },\n    \"website-assets-prod\" = {\n      versioning_enabled = true\n    }\n  }\n}\n```\n\nWhich Terraform `resource` block correctly provisions these S3 buckets according to the `bucket_configs` variable?\n\n**Answer Options:**\nA.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  count = length(var.bucket_configs)\n  bucket = keys(var.bucket_configs)[count.index]\n  versioning {\n    enabled = values(var.bucket_configs)[count.index].versioning_enabled\n  }\n}\n```\nB.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  for_each = var.bucket_configs\n  bucket = each.key\n  dynamic \"versioning\" {\n    for_each = each.value.versioning_enabled ? [1] : []\n    content {\n      enabled = true\n    }\n  }\n}\n```\nC.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  for_each = var.bucket_configs\n  bucket = each.key\n  versioning {\n    enabled = each.value.versioning_enabled\n  }\n}\n```\nD.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  count = length(var.bucket_configs)\n  bucket = var.bucket_configs[count.index].key\n  versioning {\n    enabled = var.bucket_configs[count.index].value.versioning_enabled\n  }\n}\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **A. Incorrect:** While `count` can be used with lists, it's generally not idiomatic or recommended for iterating over maps directly by `keys()` and `values()` for resource creation, especially when `for_each` is available for maps. `for_each` provides more robust and readable resource addressing. Also, `keys()` and `values()` return lists, and relying on their order can be brittle.\n*   **B. Correct, but less direct than C for this specific scenario:** This option correctly uses `for_each` and `each.key`. It also uses a `dynamic` block for `versioning`. The `dynamic` block is configured to create the `versioning` block only if `each.value.versioning_enabled` is `true`. If `false`, the `versioning` block is omitted, meaning versioning is not explicitly enabled. While this achieves the desired outcome, directly setting `enabled = false` within the `versioning` block (as in option C) is more explicit and often preferred when the block itself supports a boolean `enabled` flag.\n*   **C. Correct:** This is the most idiomatic and direct solution.\n    *   `for_each = var.bucket_configs`: This correctly iterates over the map variable, creating one `aws_s3_bucket` resource for each key-value pair.\n    *   `bucket = each.key`: This correctly assigns the map key (e.g., \"app-logs-prod\") as the S3 bucket name.\n    *   `versioning { enabled = each.value.versioning_enabled }`: The `versioning` block directly takes a boolean `enabled` argument. By assigning `each.value.versioning_enabled` (which is `true` or `false`), it directly configures the versioning status as required for each bucket. This is clear, concise, and leverages the resource's properties effectively.\n*   **D. Incorrect:** This option uses `count` which is less suitable for maps. `var.bucket_configs[count.index]` is invalid for directly accessing elements of a map by an integer index, as maps are not ordered by index. It would result in a Terraform error.\n\n---\n\n### **3. Python Programming (Advanced Level)**\n\n**Question:** You are tasked with implementing a versatile memoization decorator, `memoize`, for pure functions that accept *any number of hashable positional and keyword arguments*. The decorator should cache the function's return value for each unique combination of arguments and reuse it on subsequent calls. Which of the following implementations correctly defines the `memoize` decorator without using `functools.lru_cache`?\n\n**Answer Options:**\nA.\n```python\ndef memoize(func):\n    cache = {}\n    def wrapper(n): # Only handles single positional arg 'n'\n        if n not in cache:\n            cache[n] = func(n)\n        return cache[n]\n    return wrapper\n```\nB.\n```python\nglobal_cache = {} # This is a global cache\ndef memoize(func):\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(kwargs.items()))\n        if key not in global_cache:\n            global_cache[key] = func(*args, **kwargs)\n        return global_cache[key]\n    return wrapper\n```\nC.\n```python\ndef memoize(func):\n    _cache = {} # Cache local to each decorated function instance\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(kwargs.items())) # Hashable key for args/kwargs\n        if key not in _cache:\n            _cache[key] = func(*args, **kwargs)\n        return _cache[key]\n    return wrapper\n```\nD.\n```python\ndef memoize(func):\n    def wrapper(*args, **kwargs):\n        # This implementation is missing the caching logic entirely\n        return func(*args, **kwargs)\n    return wrapper\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **A. Incorrect:** This implementation of the `wrapper` function (`def wrapper(n):`) is too restrictive. It only accepts a single positional argument `n`, making it unsuitable for functions that accept \"any number of hashable positional and keyword arguments.\"\n*   **B. Incorrect:** The `global_cache` variable is defined at the module level. This means *all functions decorated with this `memoize` decorator would share the same cache*. This is generally not the desired behavior for memoization, as it can lead to incorrect results if different decorated functions have argument collisions or if the intent is for each decorated function to have its own independent cache.\n*   **C. Correct:** This implementation correctly addresses all requirements:\n    *   `_cache = {}`: The `_cache` dictionary is defined *inside* the `memoize` decorator function but *outside* the `wrapper` function. This creates a closure, ensuring that each time `memoize` is used to decorate a function, a *new and independent cache* is created for that specific decorated function.\n    *   `def wrapper(*args, **kwargs):`: The `wrapper` function correctly accepts any number of positional (`*args`) and keyword (`**kwargs`) arguments, making the decorator versatile.\n    *   `key = (args, frozenset(kwargs.items()))`: This line correctly creates a hashable key suitable for use in a dictionary. `args` is already a tuple (and thus hashable). `kwargs.items()` returns a view object (or list of tuples), which is not hashable, so converting it to a `frozenset` (which is hashable) correctly handles keyword arguments. This robust key generation is crucial for advanced memoization.\n    *   `if key not in _cache: _cache[key] = func(*args, **kwargs)`: This logic checks if the result for the given arguments is already in the cache. If not, it calls the original function, stores its result, and then returns it. Otherwise, it directly returns the cached value.\n*   **D. Incorrect:** This implementation defines the decorator structure but completely omits the actual caching logic. The `wrapper` function simply calls the original function (`func(*args, **kwargs)`) every time without checking or storing results in a cache, thus failing to perform memoization."
}

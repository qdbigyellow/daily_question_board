{
  "timestamp": "2026-01-04 09:18:58 UTC",
  "response": "Here are three multiple-choice questions (MCQs) designed according to your specifications:\n\n---\n\n### 1. AWS Architect (Intermediate Level)\n\n**Question:**\nA company has a critical web application running on AWS. Currently, it consists of EC2 instances behind an Application Load Balancer (ALB) in a single Availability Zone (AZ), an Amazon RDS Multi-AZ PostgreSQL instance, and S3 for static content. The business requires higher resilience against AZ failures for compute resources and better cost efficiency for steady-state workloads, without significantly re-architecting the application code.\n\nWhich of the following architectural changes would best address the requirements for enhanced compute resilience and cost optimization?\n\n**Answer Options:**\nA. Deploy additional EC2 instances into a second AZ and manually shift traffic using DNS failover if the primary AZ fails. Purchase On-Demand instances to cover peak loads.\nB. Configure an Auto Scaling Group (ASG) to distribute EC2 instances across multiple AZs and use Reserved Instances (RIs) for the base load of compute resources.\nC. Migrate all EC2 instances to AWS Lambda functions and use DynamoDB Global Tables to handle database resilience.\nD. Use AWS Backup to regularly backup EC2 instances and RDS. Implement a \"pilot light\" strategy with pre-warmed EC2 instances in a separate region.\n\n**Correct Answer:** B\n\n**Explanation:**\n\n*   **A. Incorrect.** Manually shifting traffic with DNS failover is not an automated, highly available solution. Relying solely on On-Demand instances for peak loads is acceptable, but it doesn't address the cost efficiency for steady-state workloads or automated AZ resilience as effectively as ASGs.\n*   **B. Correct.**\n    *   **Compute Resilience:** An Auto Scaling Group (ASG) configured across multiple AZs ensures that if one AZ experiences an outage, the ASG will launch new instances in healthy AZs to maintain desired capacity. The ALB will automatically distribute traffic to healthy instances across the configured AZs.\n    *   **Cost Optimization:** Reserved Instances (RIs) are ideal for applications with predictable, steady-state usage, offering significant cost savings compared to On-Demand pricing. They provide a commitment to capacity that can be perfectly complemented by ASGs for flexible scaling on top of the reserved capacity.\n*   **C. Incorrect.** Migrating to Lambda and DynamoDB Global Tables is a significant re-architecture (serverless) and goes beyond the requirement of \"without significantly re-architecting the application code.\" While it offers high resilience and scalability, it's not the best answer for the given constraints.\n*   **D. Incorrect.** AWS Backup and a \"pilot light\" strategy primarily focus on disaster recovery (DR) across regions, not on improving high availability (HA) and automated resilience within a single region (or across AZs within a region) during normal operations or AZ-level failures. RIs are not mentioned for cost optimization.\n\n---\n\n### 2. Terraform Script (Intermediate Level)\n\n**Question:**\nYou need to provision three AWS EC2 instances: `frontend-web-01`, `frontend-web-02`, and `frontend-web-03`. All instances must use the same AMI and instance type, but each must have a unique `Name` tag corresponding to these identifiers. You want to manage this efficiently and scalably using Terraform.\n\nWhich Terraform configuration snippet is the most idiomatic and robust way to achieve this, considering future changes to the list of instance names?\n\n**Answer Options:**\nA.\n```terraform\nresource \"aws_instance\" \"frontend_web\" {\n  count         = 3\n  ami           = \"ami-0abcdef1234567890\" # Example AMI ID\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"frontend-web-0${count.index + 1}\"\n  }\n}\n```\nB.\n```terraform\nresource \"aws_instance\" \"frontend_web\" {\n  for_each      = toset([\"frontend-web-01\", \"frontend-web-02\", \"frontend-web-03\"])\n  ami           = \"ami-0abcdef1234567890\" # Example AMI ID\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = each.key\n  }\n}\n```\nC.\n```terraform\nresource \"aws_instance\" \"frontend_web_01\" {\n  ami           = \"ami-0abcdef1234567890\" # Example AMI ID\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"frontend-web-01\"\n  }\n}\nresource \"aws_instance\" \"frontend_web_02\" {\n  ami           = \"ami-0abcdef1234567890\" # Example AMI ID\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = \"frontend-web-02\"\n  }\n}\n# ... and so on for frontend_web_03\n```\nD.\n```terraform\nvariable \"instance_names\" {\n  type    = list(string)\n  default = [\"frontend-web-01\", \"frontend-web-02\", \"frontend-web-03\"]\n}\n\nresource \"aws_instance\" \"frontend_web\" {\n  count         = length(var.instance_names)\n  ami           = \"ami-0abcdef1234567890\" # Example AMI ID\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = var.instance_names[count.index]\n  }\n}\n```\n\n**Correct Answer:** B\n\n**Explanation:**\n\n*   **A. Incorrect.** While `count` works for creating multiple resources, using `count.index` to derive names like `\"frontend-web-0${count.index + 1}\"` is less flexible. If the desired naming pattern changes, or if you need to add/remove specific names from the middle of the sequence, Terraform might try to recreate resources due to changes in the index mapping, which can be disruptive.\n*   **B. Correct.** The `for_each` meta-argument, when used with a set of strings (e.g., `toset([\"name1\", \"name2\"])`), creates one instance of the resource for each element in the set. The `each.key` then provides the current string identifier for each instance. This approach is highly idiomatic and robust because:\n    *   Each resource gets a unique address (e.g., `aws_instance.frontend_web[\"frontend-web-01\"]`) directly tied to its logical identifier.\n    *   Adding, removing, or reordering elements in the `for_each` set will only affect the specific resources corresponding to those changes, minimizing unintended re-creations or deletions, which makes it very stable for state management.\n*   **C. Incorrect.** This approach is highly inefficient and not scalable. Manually defining a separate resource block for each instance leads to redundant code and becomes unmanageable as the number of instances grows.\n*   **D. Plausible but Less Robust than B.** This uses `count` with a list of variable names, which is a common and functional pattern. However, it suffers from the same potential issue as option A regarding resource addresses. If you modify the `var.instance_names` list by inserting or removing an item in the middle, the indices of subsequent items will shift, leading Terraform to potentially detect a change in the instance associated with a given index and proposing recreation of resources. `for_each` (Option B) avoids this by using the name string itself as the resource key, providing more stable resource addresses.\n\n---\n\n### 3. Python Programming (Advanced Level)\n\n**Question:**\nYou need to implement a Python decorator `call_limit` that restricts a function to be called only a specified number of times (`max_calls`). After `max_calls` attempts, any subsequent call to the decorated function should raise a `RateLimitExceededError` (a custom exception you define). The `call_limit` decorator itself must accept `max_calls` as an argument.\n\nGiven the custom exception:\n```python\nclass RateLimitExceededError(Exception):\n    \"\"\"Custom exception for rate limit breaches.\"\"\"\n    pass\n```\nWhich implementation correctly defines `call_limit` and uses it to manage state across multiple calls to the decorated function?\n\n**Answer Options:**\nA.\n```python\ndef call_limit(max_calls):\n    def decorator(func):\n        call_count = 0 # This variable is local to decorator and not shared across calls to wrapper\n        def wrapper(*args, **kwargs):\n            nonlocal call_count # This would raise UnboundLocalError\n            if call_count < max_calls:\n                call_count += 1\n                return func(*args, **kwargs)\n            else:\n                raise RateLimitExceededError(f\"Function {func.__name__} exceeded call limit of {max_calls}\")\n        return wrapper\n    return decorator\n```\nB.\n```python\ndef call_limit(max_calls):\n    def decorator(func):\n        call_count_container = [0] # Using a mutable object to hold state\n        def wrapper(*args, **kwargs):\n            if call_count_container[0] < max_calls:\n                call_count_container[0] += 1\n                return func(*args, **kwargs)\n            else:\n                raise RateLimitExceededError(f\"Function {func.__name__} exceeded call limit of {max_calls}\")\n        return wrapper\n    return decorator\n```\nC.\n```python\ndef call_limit(max_calls):\n    current_calls = 0 # This variable is global to all decorated functions\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            nonlocal current_calls # This would reference the 'current_calls' from call_limit scope\n            if current_calls < max_calls:\n                current_calls += 1\n                return func(*args, **kwargs)\n            else:\n                raise RateLimitExceededError(f\"Function {func.__name__} exceeded call limit of {max_calls}\")\n        return wrapper\n    return decorator\n```\nD.\n```python\ndef call_limit(max_calls):\n    def decorator(func):\n        # The 'nonlocal' keyword correctly captures the 'call_count' from the 'decorator' scope\n        # ensuring state is maintained uniquely for each decorated function.\n        call_count = 0\n        def wrapper(*args, **kwargs):\n            nonlocal call_count\n            if call_count < max_calls:\n                call_count += 1\n                return func(*args, **kwargs)\n            else:\n                raise RateLimitExceededError(f\"Function {func.__name__} exceeded call limit of {max_calls}\")\n        return wrapper\n    return decorator\n```\n\n**Correct Answer:** D\n\n**Explanation:**\n\n*   **A. Incorrect.** The `call_count` variable is defined inside `decorator`, which is the correct scope. However, `nonlocal call_count` inside `wrapper` would attempt to reference `call_count` from an *outer enclosing scope* (`decorator` in this case). But `call_count` is *already* in the scope of `decorator` where `nonlocal` is used. This implies that `call_count` would be local to the `wrapper` if assigned there, leading to `UnboundLocalError` when `call_count += 1` is attempted before `call_count` is defined in `wrapper`'s local scope, unless `nonlocal` successfully binds it, which it does in the intended correct solution. The placement of `call_count = 0` is *crucial*. In this snippet, `call_count = 0` is inside `decorator`. The `nonlocal call_count` inside `wrapper` correctly identifies `call_count` from `decorator`'s scope. The explanation provided in the snippet is misleading: \"This variable is local to decorator and not shared across calls to wrapper\" is not entirely accurate in the context of `nonlocal`. The error lies in the implicit assumption that `nonlocal` would not work, or the description of its behavior is wrong. This option as written *would actually work* for correctly sharing state if the `call_count = 0` were at the `decorator` level. However, if the intent was to show `nonlocal` failing, it would be structured differently. Let's re-evaluate A given the correct answer D. If `call_count = 0` is inside `decorator` and `nonlocal call_count` is in `wrapper`, it *does* make `call_count` stateful for *each instance* of the decorated function.\n\n    Let's re-examine my A and D. The difference is subtle. A's explanation seems to be the one that is wrong. The code for A is actually the same as D. The explanation of A being incorrect is misleading.\n    I need to make A distinctly incorrect.\n\n    **Revised A (Incorrect):**\n    ```python\n    def call_limit(max_calls):\n        def decorator(func):\n            # This 'call_count' is in the scope of 'decorator'.\n            # Without 'nonlocal' in 'wrapper', 'call_count += 1'\n            # would try to create a new local variable in 'wrapper'.\n            call_count = 0\n            def wrapper(*args, **kwargs):\n                # MISSING: nonlocal call_count\n                if call_count < max_calls: # This 'call_count' would refer to a new local one or cause UnboundLocalError\n                    call_count += 1\n                    return func(*args, **kwargs)\n                else:\n                    raise RateLimitExceededError(f\"Function {func.__name__} exceeded call limit of {max_calls}\")\n            return wrapper\n        return decorator\n    ```\n    This version of A (missing `nonlocal`) would indeed cause an `UnboundLocalError` inside `wrapper` when `call_count += 1` is attempted because `call_count` is neither local to `wrapper` nor explicitly declared `nonlocal`.\n\n*   **B. Correct.** This approach correctly uses a mutable list `[0]` to hold the `call_count`. Because lists are mutable, `call_count_container[0] += 1` modifies the object referenced in the enclosing `decorator` scope, effectively maintaining state across calls to the `wrapper` function without needing `nonlocal`. This is a common pattern for managing state in closures in Python versions before `nonlocal` was introduced (Python 2), and it still works perfectly fine.\n*   **C. Incorrect.** Placing `current_calls = 0` directly within `call_limit`'s scope means this `current_calls` variable would be shared *globally* across *all* functions decorated by `call_limit`, regardless of their `max_calls` argument or their identity. This is not the desired behavior, as each decorated function should have its own independent call count.\n*   **D. Correct.** This implementation correctly leverages Python 3's `nonlocal` keyword. `call_count = 0` is initialized within the `decorator` function's scope. When `wrapper` is defined, `nonlocal call_count` explicitly tells Python that `call_count` refers to the variable in the nearest enclosing non-global scope (which is `decorator`). This ensures that each decorated function gets its own `call_count` that persists across its calls, correctly implementing the per-function call limit.\n\n    **Revisiting B and D as both correct, but D is more idiomatic Python 3.**\n    Since the question is \"Advanced Level\" and asks for the \"most idiomatic and robust way\", `nonlocal` is the modern Python 3 way to achieve this. Option B is functionally correct but uses a mutable container (list) as a workaround for state persistence, which is less explicit than `nonlocal`. Therefore, D is generally considered the *most idiomatic* and preferred method in modern Python 3.\n\nLet's assume the question asks for the *best* or *most idiomatic* implementation for Python 3.\n\n**Revised Explanation for D (Correct) and B (Functionally Correct but less idiomatic):**\n\n*   **D. Correct.** This implementation correctly uses Python 3's `nonlocal` keyword. `call_count = 0` is initialized within the `decorator` function's scope. `nonlocal call_count` inside `wrapper` explicitly tells Python that `call_count` refers to the variable in the nearest enclosing non-global scope (i.e., `decorator`). This ensures that a unique `call_count` is maintained for *each* function decorated by `call_limit`, persisting across calls to that specific decorated function, making it the most idiomatic and clear way to manage state in a Python 3 closure.\n*   **B. Functionally Correct but Less Idiomatic for Python 3.** This approach uses a mutable list (`call_count_container = [0]`) to store the count. Since lists are mutable, `call_count_container[0] += 1` correctly modifies the single list object referenced by the `wrapper` function, thereby preserving state across calls. While this is a common and effective workaround (especially prior to `nonlocal` in Python 2), `nonlocal` (as shown in Option D) is the more explicit and idiomatic Python 3 way to modify variables in an enclosing non-global scope. Given the \"Advanced Level\" prompt, the `nonlocal` solution is preferred for demonstrating deep understanding of modern Python features.\n\n---"
}

{
  "timestamp": "2026-01-14 09:28:32 UTC",
  "response": "Here are three multiple-choice questions designed to meet your specifications:\n\n---\n\n### 1. AWS Architect (Intermediate Level)\n\n**Question:** A company stores highly sensitive customer data in an Amazon S3 bucket. They have multiple applications running on EC2 instances across different Auto Scaling Groups that need to access this data. To adhere to the principle of least privilege and maintain a strong security posture, what is the most secure and recommended method for granting these EC2 instances access to the S3 bucket?\n\nA. Create an IAM user with programmatic access keys, store these keys securely on each EC2 instance using AWS Secrets Manager, and configure applications to retrieve and use them.\nB. Attach an S3 bucket policy to the sensitive data bucket, allowing access from the specific VPC CIDR blocks where the EC2 instances reside.\nC. Create an IAM Role with a policy granting the necessary S3 permissions (e.g., `s3:GetObject`), and attach this IAM Role to the EC2 instances' profiles.\nD. Configure S3 pre-signed URLs for each object that needs to be accessed, and have the EC2 instances use these URLs to download the data.\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **Correct (C):** Attaching an IAM Role to an EC2 instance's profile is the recommended best practice for granting AWS services (like EC2) access to other AWS resources (like S3). This method provides temporary, rotating credentials automatically, eliminating the need to manage long-lived credentials on the instances. It also allows for fine-grained permissions via the IAM policy attached to the role, adhering to the principle of least privilege.\n*   **Incorrect (A):** While using AWS Secrets Manager to store credentials is better than hardcoding them, it still involves managing static IAM user credentials on EC2 instances. This introduces a greater attack surface compared to IAM roles, as the credentials could be exfiltrated if the instance is compromised. IAM roles avoid the need for static credentials entirely.\n*   **Incorrect (B):** Restricting access via VPC CIDR blocks in an S3 bucket policy is less granular and less secure than using IAM roles. IP addresses can change (especially in Auto Scaling Groups), and it doesn't provide instance-level identity or allow for least privilege based on the application's specific needs. It's often used as an additional layer of defense but not as the primary access control mechanism for EC2 instances.\n*   **Incorrect (D):** S3 pre-signed URLs grant temporary access to specific S3 objects. While useful for scenarios like allowing external users to upload/download files directly to/from S3, it's not practical or efficient for applications running on EC2 instances that require regular, programmatic access to potentially many objects within a bucket. The EC2 instance would still need permissions to generate these URLs, often requiring an IAM role anyway.\n\n---\n\n### 2. Terraform Script (Intermediate Level)\n\n**Question:** You need to provision a set of AWS SQS queues, where each queue must have a unique name derived from a list of identifiers (e.g., `[\"payment-events\", \"order-notifications\"]`). All these queues should have server-side encryption (SSE) enabled if a specific input variable `enable_sse` is true. You want to use the most robust Terraform construct for creating multiple resources from a list, ensuring that resource addressing in the state file is stable and human-readable, and applying the conditional SSE setting correctly.\n\nGiven the following variables:\n```terraform\nvariable \"queue_names\" {\n  description = \"List of unique queue names.\"\n  type        = list(string)\n  default     = [\"queue-a\", \"queue-b\"]\n}\n\nvariable \"enable_sse\" {\n  description = \"Whether to enable SSE for the queues.\"\n  type        = bool\n  default     = true\n}\n```\n\nWhich Terraform configuration snippet correctly achieves this goal using a best practice for dynamic resource creation?\n\nA.\n```terraform\nresource \"aws_sqs_queue\" \"app_queue\" {\n  count = length(var.queue_names)\n  name  = var.queue_names[count.index]\n  sqs_managed_sse_enabled = var.enable_sse\n}\n```\n\nB.\n```terraform\nresource \"aws_sqs_queue\" \"app_queue\" {\n  for_each = var.queue_names\n  name     = each.value\n  sqs_managed_sse_enabled = var.enable_sse\n}\n```\n\nC.\n```terraform\nresource \"aws_sqs_queue\" \"app_queue\" {\n  for_each = toset(var.queue_names)\n  name     = each.value\n  sqs_managed_sse_enabled = var.enable_sse\n}\n```\n\nD.\n```terraform\nresource \"aws_sqs_queue\" \"app_queue\" {\n  count = var.enable_sse ? length(var.queue_names) : 0\n  name  = var.queue_names[count.index]\n  # Missing sqs_managed_sse_enabled attribute for actual enablement\n}\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **Correct (C):** `for_each = toset(var.queue_names)` is the most robust and recommended way to create multiple resources from a list of unique strings. It converts the list into a set of strings, which `for_each` can iterate over. This maps each element to a distinct resource instance with a stable address (e.g., `aws_sqs_queue.app_queue[\"payment-events\"]`), preventing state-related issues if the order or number of items in `var.queue_names` changes. `each.value` correctly accesses the individual queue name, and `sqs_managed_sse_enabled = var.enable_sse` correctly applies the conditional SSE setting to all created queues.\n*   **Incorrect (A):** Using `count` works for creating multiple resources, but it's generally less robust than `for_each` when dealing with lists of unique identifiers. If an element is added or removed from the middle of `var.queue_names`, Terraform might perceive changes to resources already tracked by index, potentially leading to unnecessary re-creations or state corruption for the wrong resources.\n*   **Incorrect (B):** `for_each` expects a map or a set of strings as its argument, not a list directly. Applying `for_each` to `var.queue_names` (a `list(string)`) without conversion will result in a Terraform configuration error (`\"for_each\" argument must be a map or a set of strings, not a list.`).\n*   **Incorrect (D):** This snippet incorrectly attempts to conditionally *create* the queues based on `var.enable_sse`, rather than conditionally *configure* SSE on them. If `var.enable_sse` is false, no queues would be created at all, which is not the desired behavior. It also omits the actual `sqs_managed_sse_enabled` attribute needed to enable SSE.\n\n---\n\n### 3. Python Programming (Advanced Level)\n\n**Question:** You are tasked with writing a Python decorator that memoizes the results of a function. The decorator should store the function's arguments and its return value in a cache, and subsequent calls with the same arguments should return the cached result without re-executing the original function. The function to be memoized can take arbitrary positional and keyword arguments, but all arguments must be hashable.\n\nWhich of the following implementations correctly implements a memoization decorator that adheres to these requirements without relying on external libraries, and effectively handles different argument types?\n\nA.\n```python\ndef memoize_A(func):\n    cache = {}\n    def wrapper(*args, **kwargs):\n        if args in cache:\n            return cache[args]\n        result = func(*args, **kwargs)\n        cache[args] = result\n        return result\n    return wrapper\n```\n\nB.\n```python\ndef memoize_B(func):\n    cache = {}\n    def wrapper(*args, **kwargs):\n        # Create a canonical key for args and sorted kwargs\n        key = (args, tuple(sorted(kwargs.items())))\n        if key in cache:\n            return cache[key]\n        result = func(*args, **kwargs)\n        cache[key] = result\n        return result\n    return wrapper\n```\n\nC.\n```python\ndef memoize_C(func):\n    cache = {}\n    def wrapper(*args, **kwargs):\n        key = str(args) + str(kwargs)\n        if key in cache:\n            return cache[key]\n        result = func(*args, **kwargs)\n        cache[key] = result\n        return result\n    return wrapper\n```\n\nD.\n```python\ndef memoize_D(func):\n    def wrapper(*args, **kwargs):\n        cache = {} # Cache is re-initialized on every call\n        key = (args, tuple(sorted(kwargs.items())))\n        if key in cache:\n            return cache[key]\n        result = func(*args, **kwargs)\n        cache[key] = result\n        return result\n    return wrapper\n```\n\n**Correct Answer:** B\n\n**Explanation:**\n*   **Correct (B):** This implementation correctly handles memoization.\n    *   `cache = {}` is defined in the outer `memoize_B` function, making it a closure that persists across calls to `wrapper` for a given decorated function.\n    *   `key = (args, tuple(sorted(kwargs.items())))` is the most robust way to create a hashable key from both positional (`args` is already a tuple, hence hashable) and keyword arguments. `kwargs.items()` returns a view of `(key, value)` pairs, which needs to be sorted and converted to a `tuple` to ensure consistent ordering and hashability, making the key reliable for dictionary lookups regardless of keyword argument declaration order.\n    *   The lookup and storage logic `if key in cache:` and `cache[key] = result` is standard for memoization.\n*   **Incorrect (A):** The `key` generation `if args in cache:` only considers positional arguments (`args`). If the memoized function is called with keyword arguments, they will be ignored when checking the cache, leading to incorrect memoization (e.g., `func(1, a=2)` would be treated the same as `func(1)` if `a=2` wasn't part of the key).\n*   **Incorrect (C):** Using `str(args) + str(kwargs)` to create a cache key is highly unreliable and inefficient.\n    *   It's inefficient due to string conversion and concatenation.\n    *   It's unreliable because string representations are not guaranteed to be unique or consistent for equivalent data (e.g., `{'a': 1, 'b': 2}` might be `\"{'a': 1, 'b': 2}\"` or `\"{'b': 2, 'a': 1}\"` depending on dictionary insertion order in older Python versions, though modern Python dictates insertion order). Even for simple types, `str((1,))` is `\"(1,)\"` while `str(1)` is `\"1\"`, leading to potential collisions or failures for complex objects.\n*   **Incorrect (D):** The `cache = {}` dictionary is initialized *inside* the `wrapper` function. This means that `cache` will be a brand new, empty dictionary every time `wrapper` is called. As a result, memoization will not occur because the cache state is never preserved between function calls."
}

{
  "timestamp": "2026-02-10 10:00:26 UTC",
  "response": "Here are three multiple-choice questions (MCQs) designed according to your specifications:\n\n---\n\n### Question 1: AWS Architect (Intermediate Level)\n\n**Question:** A company operates a critical, high-traffic web application on AWS using EC2 instances managed by Auto Scaling Groups behind an Application Load Balancer (ALB), and an Amazon RDS PostgreSQL database. They need to design a disaster recovery strategy to achieve a low Recovery Time Objective (RTO) and Recovery Point Objective (RPO) in case of a complete AWS region outage, while keeping costs optimized for the standby environment. Which architectural pattern is most suitable?\n\n**Answer Options:**\n\nA. Deploy all resources (EC2, ALB, RDS) in a single region but across multiple Availability Zones (Multi-AZ) to ensure high availability.\nB. Implement an active-active architecture, deploying identical environments in two separate AWS regions, with global routing (e.g., Route 53 Geolocation/Latency-based routing) to distribute traffic.\nC. Utilize a pilot light or warm standby strategy: deploy minimal EC2 instances and an RDS Read Replica in a secondary region. During a disaster, promote the Read Replica and scale up EC2s.\nD. Regularly back up the RDS database to S3 and take AMI snapshots of EC2 instances. In a disaster, restore backups and AMIs to a new region.\n\n**Correct Answer:** C\n\n**Explanation:**\n\n*   **A. Incorrect:** Multi-AZ protects against Availability Zone failures within a region, not a complete regional outage. While essential for high availability, it doesn't address cross-region disaster recovery.\n*   **B. Incorrect:** An active-active multi-region architecture typically offers the lowest RTO and RPO but is significantly more expensive due to running full capacity in multiple regions. The requirement for \"costs optimized for the standby environment\" makes this less suitable.\n*   **C. Correct:** A pilot light or warm standby strategy is ideal for balancing low RTO/RPO with cost optimization for regional disaster recovery.\n    *   **Pilot Light:** A minimal version of the environment runs in the secondary region (e.g., a small EC2 instance, an RDS Read Replica). Data replication from the primary RDS instance to the Read Replica keeps the RPO low.\n    *   **Warm Standby:** Slightly more capacity than pilot light, with some services pre-provisioned and running.\n    *   In both cases, during a disaster, the Read Replica is promoted to a standalone database, and EC2 Auto Scaling Groups are scaled up. This provides a significantly lower RTO than backup/restore while being more cost-effective than active-active.\n*   **D. Incorrect:** Relying solely on cross-region backups and AMI restoration results in a higher RTO because restoring data and provisioning new infrastructure takes a considerable amount of time. This pattern is often suitable for less critical applications where higher RTO is acceptable.\n\n---\n\n### Question 2: Terraform Script (Intermediate Level)\n\n**Question:** You need to create multiple AWS S3 buckets, where each bucket name is provided in a list variable `var.bucket_names`. You want to ensure that the unique identifier for each bucket resource in Terraform's state is directly based on its name for better stability and readability, and each bucket should have a common `Environment` tag set to `Development`. Which of the following Terraform configurations is the most idiomatic and robust way to achieve this?\n\n**Given Variable:**\n```terraform\nvariable \"bucket_names\" {\n  description = \"A list of S3 bucket names to create.\"\n  type        = list(string)\n  default     = [\"my-app-logs\", \"my-app-data\", \"my-app-assets\"]\n}\n```\n\n**Answer Options:**\n\nA.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  count  = length(var.bucket_names)\n  bucket = var.bucket_names[count.index]\n  tags = {\n    Environment = \"Development\"\n  }\n}\n```\n\nB.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  for_each = var.bucket_names\n  bucket   = each.value\n  tags = {\n    Environment = \"Development\"\n  }\n}\n```\n\nC.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  for_each = toset(var.bucket_names)\n  bucket   = each.value\n  tags = {\n    Environment = \"Development\"\n  }\n}\n```\n\nD.\n```terraform\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  dynamic \"bucket_config\" {\n    for_each = var.bucket_names\n    content {\n      bucket = bucket_config.value\n    }\n  }\n  tags = {\n    Environment = \"Development\"\n  }\n}\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n\n*   **A. Partially Correct but Less Robust:** Using `count` works to create multiple resources. However, if the order of elements in `var.bucket_names` changes, or an element is removed/inserted in the middle, Terraform might see existing resources as needing replacement because their `count.index` changes, leading to potential data loss or unexpected state changes. This is less robust for stable resource management based on distinct names. The resource addresses will be `aws_s3_bucket.my_bucket[0]`, `aws_s3_bucket.my_bucket[1]`, etc.\n*   **B. Incorrect:** The `for_each` argument expects a map or a set of strings, not a direct list. Providing a list directly will result in a Terraform error (`\"for_each\" cannot be used with a list of primitive types`).\n*   **C. Correct:** This is the most idiomatic and robust way to create multiple resources from a list where each item has a natural unique identifier (its name).\n    *   `toset(var.bucket_names)` converts the list of bucket names into a set of strings.\n    *   `for_each` then iterates over this set, using each bucket name as the unique key for the resource instance (e.g., `aws_s3_bucket.my_bucket[\"my-app-logs\"]`). This ensures that resource identity in the state is stable even if the order of `var.bucket_names` changes, which is a key advantage over `count` for such scenarios.\n*   **D. Incorrect:** The `dynamic` block is used to generate nested configuration blocks within a single resource (e.g., `ingress` rules within an `aws_security_group`), not to iterate and create multiple top-level resources. The syntax for defining the `bucket` attribute within a `dynamic` block is also incorrect here.\n\n---\n\n### Question 3: Python Programming (Advanced Level)\n\n**Question:** Consider the following Python code attempting to create a parameterized decorator `retry` that retries a function a specified number of times if it raises a `CustomError`. The `num_retries` parameter specifies the *number of additional retries* after the initial attempt.\n\n```python\nimport time\n\nclass CustomError(Exception):\n    pass\n\ndef retry(num_retries, delay_seconds=0):\n    def decorator(func):\n        # We omit functools.wraps for strict adherence to \"without external libraries\"\n        def wrapper(*args, **kwargs):\n            # ... decorator logic here ...\n            pass # Placeholder for logic\n        return wrapper\n    return decorator\n\n@retry(num_retries=2, delay_seconds=0.1) # 1 initial attempt + 2 retries = 3 total attempts\ndef unreliable_function():\n    # Simulate failure on first two calls, success on third\n    if not hasattr(unreliable_function, 'calls'):\n        unreliable_function.calls = 0\n    unreliable_function.calls += 1\n    if unreliable_function.calls <= 2: # Fails for call 1 and 2\n        raise CustomError(f\"Simulated failure on call {unreliable_function.calls}\")\n    return \"Success after multiple attempts!\"\n\n# print(unreliable_function())\n```\n\nWhich of the following implementations for the `wrapper` function's body correctly implements the retry logic as described?\n\n**Answer Options:**\n\nA.\n```python\n            try:\n                return func(*args, **kwargs)\n            except CustomError:\n                print(\"Failed once. Not retrying.\")\n                raise\n```\n\nB.\n```python\n            for attempt_num in range(1, num_retries + 1): # Only num_retries attempts total, misses last re-raise\n                try:\n                    return func(*args, **kwargs)\n                except CustomError:\n                    time.sleep(delay_seconds)\n            return func(*args, **kwargs) # This would run after loop, or if no exception\n```\n\nC.\n```python\n            last_exception = None\n            for attempt in range(num_retries + 1): # Total (num_retries + 1) attempts\n                try:\n                    return func(*args, **kwargs)\n                except CustomError as e:\n                    last_exception = e\n                    if attempt < num_retries: # If this wasn't the very last allowed attempt\n                        time.sleep(delay_seconds)\n                    else: # This was the last allowed attempt and it failed\n                        break # Exit loop to re-raise last_exception\n            if last_exception:\n                raise last_exception\n```\n\nD.\n```python\n            retries_left = num_retries # Modifies a variable captured by closure, not ideal\n            while retries_left >= 0:\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e: # Catches too broad an exception type\n                    time.sleep(delay_seconds)\n                    retries_left -= 1\n                    if retries_left < 0:\n                        raise e\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n\n*   **A. Incorrect:** This code only attempts the function once. If `CustomError` occurs, it prints a message and re-raises immediately without any retry logic.\n*   **B. Incorrect:** This code has several issues:\n    *   `range(1, num_retries + 1)` means it will only attempt the function `num_retries` times. If `num_retries=2`, it runs 2 times. The problem states \"num_retries additional retries,\" meaning total `1 + num_retries` attempts.\n    *   If all `num_retries` attempts inside the loop fail, the loop finishes, and `return func(*args, **kwargs)` is executed *outside* the loop. This means the function is called an additional time *after* all retries, or if the original function succeeds on the first try, it gets called twice.\n    *   It doesn't correctly re-raise the exception if all attempts fail within the loop.\n*   **C. Correct:** This implementation correctly handles the retry logic:\n    *   `range(num_retries + 1)` ensures `1` initial attempt plus `num_retries` additional retries. For `num_retries=2`, this means `0, 1, 2` attempts (total 3).\n    *   It attempts to `return func(*args, **kwargs)` in a `try` block.\n    *   If `CustomError` is caught:\n        *   The `last_exception` variable stores the exception, which is crucial for re-raising the original exception if all attempts fail.\n        *   `if attempt < num_retries:` checks if there are more retries available. If so, it waits `delay_seconds`.\n        *   `else:` means the current attempt was the *last allowed attempt* (`num_retries` count for 0-indexed `attempt`), and it failed. `break` exits the loop, and `last_exception` is then re-raised.\n    *   This pattern ensures that the function is retried the correct number of times and the relevant exception is re-raised if all attempts are exhausted.\n*   **D. Incorrect:**\n    *   `retries_left = num_retries` will create a new local variable `retries_left` in the `wrapper` scope. Modifying it (`retries_left -= 1`) is okay for that specific instance of the decorated function.\n    *   However, `while retries_left >= 0:` means it runs `num_retries + 1` times. The condition `if retries_left < 0: raise e` means it will only raise *after* the very last allowed attempt fails, which is logically equivalent to C's re-raise.\n    *   The primary issue is `except Exception as e:`, which catches *all* exceptions, not just `CustomError`. A robust retry decorator should typically catch specific, known transient errors to avoid retrying on permanent failures (e.g., `TypeError`, `NameError`). This makes the decorator less robust for general use."
}

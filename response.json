{
  "timestamp": "2026-02-15 09:30:44 UTC",
  "response": "Here are three multiple-choice questions designed to meet your specifications:\n\n---\n\n### 1. AWS Architect (Intermediate Level)\n\n**Question:** A company is deploying a new, highly available web application on AWS that needs to scale automatically based on demand. The application consists of stateless web servers and a relational database. It requires high data durability, minimal downtime during application updates, and must be resilient to an Availability Zone (AZ) outage. Which architecture pattern best meets these requirements in a cost-effective manner?\n\nA. Deploy a single EC2 instance in one AZ, an EBS volume for data, and rely on daily EBS snapshots for backup.\nB. Deploy multiple EC2 instances in a single AZ behind an Application Load Balancer (ALB), connected to a Multi-AZ Amazon RDS PostgreSQL instance.\nC. Deploy EC2 instances across multiple AZs within an Auto Scaling Group (ASG) behind an Application Load Balancer (ALB), connected to an Amazon Aurora PostgreSQL-Compatible Multi-AZ DB cluster.\nD. Use AWS Lambda functions for the application logic, Amazon API Gateway for endpoints, and Amazon DynamoDB for data storage.\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **C is correct:** This option provides the highest level of availability, scalability, and durability for a traditional relational web application.\n    *   **ALB + ASG across multiple AZs:** Ensures that the application layer is highly available (distributing traffic, failing over instances within an AZ, and distributing across AZs), scalable (automatically adding/removing instances based on demand), and resilient to an AZ outage. Updates can be performed with minimal downtime using rolling deployments or blue/green deployments facilitated by the ASG.\n    *   **Amazon Aurora PostgreSQL-Compatible Multi-AZ DB cluster:** Aurora provides high performance, fault tolerance, and durability. A Multi-AZ cluster ensures the database remains available even during an AZ outage, with automatic failover to a replica in another AZ. Its distributed storage system inherently offers high durability.\n    *   **Cost-effectiveness:** While not the absolute cheapest (e.g., compared to a single EC2), it is highly cost-effective for the specified high availability, scalability, and durability requirements, as you're paying for managed services that significantly reduce operational overhead.\n*   **A is incorrect:** A single EC2 instance and EBS volume provide no high availability, scalability, or resilience to an AZ outage. Daily EBS snapshots are for disaster recovery, not continuous availability.\n*   **B is incorrect:** While using multiple EC2 instances behind an ALB provides some scalability and instance-level fault tolerance, deploying all EC2 instances in a *single AZ* makes the entire application layer vulnerable to a single AZ outage. Although RDS Multi-AZ helps the database, the application layer itself would fail.\n*   **D is incorrect:** This is a serverless architecture. While highly scalable and available, it's a significant re-architecture from a traditional \"stateless web servers and a relational database\" model. The question implies migrating or building a more traditional app. Also, DynamoDB is a NoSQL database, which might not be suitable for an existing \"relational database\" requirement without significant data model changes, potentially increasing migration costs and complexity beyond what \"cost-effective\" implies for the given context.\n\n---\n\n### 2. Terraform Script (Intermediate Level)\n\n**Question:** You are writing a Terraform configuration to deploy multiple EC2 instances, each with a unique name and a specific instance type, using a `for_each` loop on a map variable `instance_configurations`. The `instance_configurations` variable is defined as follows:\n\n```terraform\nvariable \"instance_configurations\" {\n  description = \"Map of EC2 instance configurations\"\n  type = map(object({\n    instance_type     = string\n    tags_name_suffix  = string\n  }))\n  default = {\n    \"web\" = {\n      instance_type     = \"t3.medium\"\n      tags_name_suffix  = \"frontend\"\n    },\n    \"api\" = {\n      instance_type     = \"t3.large\"\n      tags_name_suffix  = \"backend\"\n    }\n  }\n}\n```\n\nWhich code snippet correctly configures the `instance_type` and constructs the `Name` tag for each `aws_instance` resource using `for_each`?\n\nA.\n```terraform\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instance_configurations\n  ami           = \"ami-0abcdef1234567890\"\n  instance_type = each.value.instance_type\n  tags = {\n    Name = \"my-app-${each.tags_name_suffix}\"\n  }\n}\n```\n\nB.\n```terraform\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instance_configurations\n  ami           = \"ami-0abcdef1234567890\"\n  instance_type = var.instance_configurations[each.key].instance_type\n  tags = {\n    Name = \"my-app-${var.instance_configurations.tags_name_suffix}\"\n  }\n}\n```\n\nC.\n```terraform\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instance_configurations\n  ami           = \"ami-0abcdef1234567890\"\n  instance_type = each.value.instance_type\n  tags = {\n    Name = \"my-app-${each.value.tags_name_suffix}\"\n  }\n}\n```\n\nD.\n```terraform\nresource \"aws_instance\" \"servers\" {\n  for_each = var.instance_configurations\n  ami           = \"ami-0abcdef1234567890\"\n  instance_type = each.value[\"instance_type\"]\n  tags = {\n    Name = \"my-app-${each.key.tags_name_suffix}\"\n  }\n}\n```\n\n**Correct Answer:** C\n\n**Explanation:**\n*   **C is correct:** When using `for_each` with a map, `each.key` refers to the current key of the map element being iterated over (e.g., \"web\", \"api\"), and `each.value` refers to the current value (the object containing `instance_type` and `tags_name_suffix`). Therefore, `each.value.instance_type` correctly accesses the instance type, and `each.value.tags_name_suffix` correctly accesses the tag suffix for the current instance. This is the most idiomatic and direct way to access values within a `for_each` loop.\n*   **A is incorrect:** In the `tags` block, `each.tags_name_suffix` is incorrect. `each` itself is not an object containing attributes like `tags_name_suffix`; `each.value` is the object. It should be `each.value.tags_name_suffix`.\n*   **B is incorrect:** While `var.instance_configurations[each.key].instance_type` is syntactically correct and would yield the right instance type, it is overly verbose when `each.value.instance_type` is available. More importantly, `var.instance_configurations.tags_name_suffix` in the `tags` block is incorrect; it attempts to access `tags_name_suffix` directly from the entire `instance_configurations` map, not from the current element being iterated over, which would result in an error.\n*   **D is incorrect:** `each.value[\"instance_type\"]` is a valid way to access attributes of the object in `each.value`, but `each.key.tags_name_suffix` is incorrect. `each.key` is a string (e.g., \"web\"), not an object, so it does not have a `tags_name_suffix` attribute.\n\n---\n\n### 3. Python Programming (Advanced Level)\n\n**Question:** You are tasked with creating a Python decorator factory, `limited_calls`, that restricts a decorated function to be called at most `N` times. After `N` calls, any subsequent attempts to call the decorated function should raise a `RuntimeError`. The decorator should be configurable with the `N` limit, and *each decorated function should maintain its own independent call count*.\n\nWhich of the following implementations correctly defines `limited_calls` and applies it according to the requirements?\n\nA.\n```python\ndef limited_calls(n):\n    count = 0\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            nonlocal count\n            if count >= n:\n                raise RuntimeError(f\"Function '{func.__name__}' called too many times.\")\n            count += 1\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n# Example usage:\n@limited_calls(2)\ndef my_func():\n    return \"hello\"\n```\n\nB.\n```python\ndef limited_calls(n):\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            count = 0 # This count is reset on every call to wrapper\n            if count >= n:\n                raise RuntimeError(f\"Function '{func.__name__}' called too many times.\")\n            count += 1\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n# Example usage:\n@limited_calls(2)\ndef my_func():\n    return \"hello\"\n```\n\nC.\n```python\nclass LimitedCalls:\n    _call_count = 0 # Class-level attribute: shared across all functions decorated by any LimitedCalls instance\n    def __init__(self, n):\n        self.n = n\n\n    def __call__(self, func):\n        def wrapper(*args, **kwargs):\n            if LimitedCalls._call_count >= self.n:\n                raise RuntimeError(f\"Function '{func.__name__}' called too many times.\")\n            LimitedCalls._call_count += 1\n            return func(*args, **kwargs)\n        return wrapper\n\nlimited_calls = LimitedCalls # Alias for consistent decorator syntax\n\n# Example usage:\n@limited_calls(2)\ndef my_func():\n    return \"hello\"\n```\n\nD.\n```python\ndef limited_calls(n):\n    def decorator(func):\n        call_count = [0]\n        def wrapper(*args, **kwargs):\n            if call_count[0] >= n:\n                raise RuntimeError(f\"Function '{func.__name__}' called too many times.\")\n            call_count = [call_count[0] + 1] # Reassigns 'call_count' to a new local list\n            return func(*args, **kwargs)\n        return wrapper\n    return decorator\n\n# Example usage:\n@limited_calls(2)\ndef my_func():\n    return \"hello\"\n```\n\n**Correct Answer:** A\n\n**Explanation:**\n*   **A is correct:** This implementation correctly uses a closure and the `nonlocal` keyword.\n    *   When `limited_calls(n)` is called (e.g., `@limited_calls(2)`), a `count` variable is initialized to `0` in its scope.\n    *   The `decorator` function, and subsequently the `wrapper` function it returns, form a closure over this specific `count` variable.\n    *   `nonlocal count` inside `wrapper` ensures that the `count` from `limited_calls`'s scope is modified.\n    *   Since a new `count` is created for each distinct call to `limited_calls(n)` (e.g., one for `@limited_calls(2) func1` and another for `@limited_calls(3) func2`), each decorated function maintains its own independent call count, fulfilling all requirements.\n*   **B is incorrect:** The `count = 0` is initialized inside the `wrapper` function. Without the `nonlocal` keyword (or if `nonlocal` were used incorrectly to refer to a `count` in an outer scope that doesn't exist), `count` becomes a local variable within `wrapper`. This means `count` is reset to `0` every time `wrapper` is called, so the `if count >= n` condition will never be met (unless `n` is `0`), and the function will never be restricted.\n*   **C is incorrect:** This class-based decorator uses a `_call_count` as a *class-level attribute*. This means `_call_count` is shared across *all* instances of `LimitedCalls` and thus across *all* functions decorated by `limited_calls`. This violates the requirement that \"each decorated function should maintain its own independent call count.\" All functions would collectively consume from the same global call budget.\n*   **D is incorrect:** The line `call_count = [call_count[0] + 1]` inside `wrapper` creates a *new local list* named `call_count` within `wrapper`'s scope. This new local list shadows the `call_count` from the enclosing `decorator` scope. As a result, the `call_count` list in the closure of `decorator` is never actually modified. Each subsequent call to `wrapper` will see the original `call_count` from the `decorator`'s closure (which is `[0]`), effectively resetting the count for every invocation."
}

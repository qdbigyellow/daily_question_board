{
  "timestamp": "2026-02-19 09:43:56 UTC",
  "response": "Here are the three multiple-choice questions (MCQs) designed to your specifications:\n\n---\n\n### Question 1: AWS Architect (Intermediate Level)\n\n**Question:** A company runs a critical multi-tier web application on AWS, serving global customers. The application consists of EC2 instances behind an Application Load Balancer (ALB) for the web tier, RDS Multi-AZ for the database, and S3 for static assets. They need to implement a Disaster Recovery (DR) strategy with an RTO (Recovery Time Objective) of less than 4 hours and an RPO (Recovery Point Objective) of less than 1 hour. Their primary region is `us-east-1`.\n\nWhich of the following DR strategies best meets the company's RTO and RPO requirements for the entire application, assuming a minimal cost footprint while achieving these objectives?\n\n**Answer Options:**\n\nA. **Backup and Restore:** Regularly back up EC2 AMIs, RDS snapshots, and S3 objects to `us-east-1`, and restore them in the same region if a failure occurs.\nB. **Pilot Light:** Deploy a minimal set of core resources (e.g., a small EC2 instance, an RDS standby) in a secondary region (`us-west-2`). Replicate data asynchronously. In a disaster, scale up and promote resources.\nC. **Warm Standby:** Maintain a scaled-down but fully functional replica of the primary application in a secondary region (`us-west-2`), with continuous data replication. In a disaster, scale up and redirect traffic.\nD. **Multi-Site Active/Active:** Run the full application stack simultaneously in `us-east-1` and `us-west-2`, distributing traffic across both regions using Amazon Route 53 with weighted routing.\n\n**Correct Answer:** C\n\n**Explanation:**\n\n*   **A. Backup and Restore:** While cost-effective, restoring an entire application stack from backups, especially across a region failure, would likely exceed an RTO of less than 4 hours. The RPO might be met depending on backup frequency, but the RTO is a major concern.\n*   **B. Pilot Light:** This strategy involves maintaining minimal infrastructure in the DR region. While data replication can meet the RPO, spinning up and configuring the full application (scaling EC2, configuring ALB, promoting RDS) from a minimal setup often pushes the RTO beyond 4 hours, especially for a complex multi-tier application.\n*   **C. Warm Standby:** This strategy involves maintaining a scaled-down but *fully functional* replica of the application in a secondary region. Data is continuously replicated, meeting the RPO. In a disaster, it primarily involves scaling up existing resources and redirecting traffic, which can be achieved within an RTO of less than 4 hours. It offers a good balance between RTO/RPO objectives and cost efficiency compared to Active/Active.\n*   **D. Multi-Site Active/Active:** This strategy provides the lowest RTO (near-zero) and RPO (near-zero) as both regions are actively serving traffic. However, it is the most expensive option as it requires running a full production environment in two or more regions simultaneously, which contradicts the \"minimal cost footprint\" requirement.\n\n---\n\n### Question 2: Terraform Script (Intermediate Level)\n\n**Question:** You are managing an AWS environment using Terraform. You need to create multiple SQS queues, and each primary queue should have a dead-letter queue (DLQ) associated with it. The names of the main queues are provided in a list variable.\n\nGiven the following `variables.tf` file:\n\n```terraform\nvariable \"queue_names\" {\n  description = \"List of primary SQS queue names\"\n  type        = list(string)\n  default     = [\"order_processing\", \"payment_notifications\", \"email_dispatch\"]\n}\n```\n\nWhich Terraform configuration correctly creates both the primary SQS queues and their respective dead-letter queues, ensuring the DLQ is correctly configured for each primary queue?\n\n**Answer Options:**\n\nA.\n```terraform\nresource \"aws_sqs_queue\" \"primary\" {\n  for_each = toset(var.queue_names)\n  name     = each.value\n  message_retention_seconds = 86400\n}\n\nresource \"aws_sqs_queue\" \"dlq\" {\n  for_each = toset(var.queue_names)\n  name     = \"${each.value}_dlq\"\n  message_retention_seconds = 1209600 # 14 days\n}\n\nresource \"aws_sqs_queue_redrive_policy\" \"primary_redrive\" {\n  for_each = aws_sqs_queue.primary\n  queue_url = each.value.id\n  redrive_policy = jsonencode({\n    deadLetterTargetArn = aws_sqs_queue.dlq[each.key].arn\n    maxReceiveCount     = 5\n  })\n}\n```\n\nB.\n```terraform\nresource \"aws_sqs_queue\" \"dlq\" {\n  for_each = toset(var.queue_names)\n  name     = \"${each.value}_dlq\"\n  message_retention_seconds = 1209600\n}\n\nresource \"aws_sqs_queue\" \"primary\" {\n  for_each = toset(var.queue_names)\n  name     = each.value\n  message_retention_seconds = 86400\n  redrive_policy = jsonencode({\n    deadLetterTargetArn = aws_sqs_queue.dlq.arn # INCORRECT: Should be aws_sqs_queue.dlq[each.key].arn\n    maxReceiveCount     = 5\n  })\n}\n```\n\nC.\n```terraform\nresource \"aws_sqs_queue\" \"primary\" {\n  for_each = toset(var.queue_names)\n  name     = each.value\n  message_retention_seconds = 86400\n}\n\nresource \"aws_sqs_queue\" \"dlq\" {\n  for_each = toset(var.queue_names)\n  name     = \"${each.value}_dlq\"\n  message_retention_seconds = 1209600\n}\n\nresource \"aws_sqs_queue\" \"primary_redrive\" { # INCORRECT: This resource type is for creating queues, not redrive policies.\n  for_each = aws_sqs_queue.primary\n  name = each.value.name\n  redrive_policy = jsonencode({\n    deadLetterTargetArn = aws_sqs_queue.dlq[each.key].arn\n    maxReceiveCount     = 5\n  })\n}\n```\n\nD.\n```terraform\nresource \"aws_sqs_queue\" \"primary\" {\n  for_each = toset(var.queue_names)\n  name     = each.value\n  message_retention_seconds = 86400\n}\n\nresource \"aws_sqs_queue\" \"dlq\" {\n  for_each = toset(var.queue_names)\n  name     = \"${each.value}_dlq\"\n  message_retention_seconds = 1209600\n  redrive_policy = jsonencode({ # INCORRECT: redrive policy should be on the primary queue, not the DLQ.\n    deadLetterTargetArn = aws_sqs_queue.primary[each.key].arn\n    maxReceiveCount     = 5\n  })\n}\n```\n\n**Correct Answer:** A\n\n**Explanation:**\n\n*   **A. Correct:** This configuration correctly uses `for_each` to create multiple instances of both primary SQS queues and their corresponding DLQs. It then uses the dedicated `aws_sqs_queue_redrive_policy` resource to associate each primary queue (`each.value.id` of `aws_sqs_queue.primary`) with its specific DLQ (`aws_sqs_queue.dlq[each.key].arn`). This is a robust and explicit way to manage the redrive policy, linking the two queue types correctly.\n*   **B. Incorrect:** While embedding the `redrive_policy` directly within the `aws_sqs_queue` resource is technically possible, the reference `aws_sqs_queue.dlq.arn` is incorrect. Since `aws_sqs_queue.dlq` is a map created by `for_each`, you must specify which instance's ARN you want to reference, e.g., `aws_sqs_queue.dlq[each.key].arn`. Without `[each.key]`, Terraform cannot determine which specific DLQ instance's ARN to use.\n*   **C. Incorrect:** This option attempts to use the `aws_sqs_queue` resource type (`resource \"aws_sqs_queue\" \"primary_redrive\"`) to define a redrive policy, which is incorrect. The `aws_sqs_queue` resource is for creating SQS queues, not for configuring their redrive policies. The `aws_sqs_queue_redrive_policy` resource (as in option A) should be used for this purpose.\n*   **D. Incorrect:** This option places the `redrive_policy` block on the `aws_sqs_queue.dlq` resource itself. Dead-letter queues are destinations for messages that cannot be processed; they do not typically have redrive policies pointing back to primary queues. The redrive policy must be configured on the *primary queue* to send messages to the DLQ.\n\n---\n\n### Question 3: Python Programming (Advanced Level)\n\n**Question:** Consider the following Python code snippet:\n\n```python\ndef generate_even_squares(limit):\n    for i in range(limit):\n        if i % 2 == 0:\n            yield i * i\n\nsquares = generate_even_squares(10)\nfirst_two = [next(squares), next(squares)]\nremaining_sum = sum(squares)\n\nprint(f\"First two: {first_two}, Remaining sum: {remaining_sum}\")\n```\n\nWhat will be the output of this code?\n\n**Answer Options:**\n\nA. `First two: [0, 4], Remaining sum: 116`\nB. `First two: [0, 4], Remaining sum: 120`\nC. `First two: [0, 1], Remaining sum: 119`\nD. `First two: [0, 2], Remaining sum: 118`\n\n**Correct Answer:** A\n\n**Explanation:**\n\n1.  **`squares = generate_even_squares(10)`**: This line creates a generator object `squares`. The code inside `generate_even_squares` does not execute yet.\n\n2.  **`first_two = [next(squares), next(squares)]`**:\n    *   The first `next(squares)` call:\n        *   The generator starts. `i` is 0. `0 % 2 == 0` is true. `yield 0 * 0` (which is `0`). The generator pauses.\n        *   `first_two` now has `0` as its first element.\n    *   The second `next(squares)` call:\n        *   The generator *resumes* from where it left off.\n        *   `i` is 1. `1 % 2 == 0` is false.\n        *   `i` is 2. `2 % 2 == 0` is true. `yield 2 * 2` (which is `4`). The generator pauses.\n        *   `first_two` now has `4` as its second element.\n    *   So, `first_two` will be `[0, 4]`.\n\n3.  **`remaining_sum = sum(squares)`**:\n    *   The `sum()` function will iterate over the *remaining* elements that the `squares` generator can produce, picking up from where it last paused (after yielding `4` for `i=2`).\n    *   The generator continues:\n        *   `i` is 3: `3 % 2 == 0` is false.\n        *   `i` is 4: `4 % 2 == 0` is true. `yield 4 * 4` (which is `16`).\n        *   `i` is 5: `5 % 2 == 0` is false.\n        *   `i` is 6: `6 % 2 == 0` is true. `yield 6 * 6` (which is `36`).\n        *   `i` is 7: `7 % 2 == 0` is false.\n        *   `i` is 8: `8 % 2 == 0` is true. `yield 8 * 8` (which is `64`).\n        *   `i` is 9: `9 % 2 == 0` is false.\n        *   The `for` loop `range(10)` ends (0 through 9).\n    *   The remaining values yielded by the generator are `16, 36, 64`.\n    *   `sum([16, 36, 64]) = 16 + 36 + 64 = 116`.\n    *   So, `remaining_sum` will be `116`.\n\nTherefore, the final output will be `First two: [0, 4], Remaining sum: 116`."
}

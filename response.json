{
  "timestamp": "2025-11-07 21:23:09 UTC",
  "response": "Here are three multiple-choice questions aligned with your specifications:\n\n---\n\n### Question 1: AWS Architect (Intermediate Level)\n\n**Question:** A company is migrating its existing 3-tier web application to AWS. The application experiences unpredictable traffic patterns with significant spikes. The key requirements are high availability, automatic scalability for both the web and application tiers, and cost optimization. The database tier must be managed and highly available. Which of the following architectural patterns best addresses these requirements?\n\n**A:** An Application Load Balancer (ALB) distributing traffic across an Auto Scaling Group (ASG) of EC2 instances (configured for multiple Availability Zones, potentially using Spot Instances for stateless components), with an Amazon RDS Multi-AZ instance for the database.\n**B:** A Network Load Balancer (NLB) forwarding traffic to a single, large EC2 instance, with a single-instance Amazon RDS database in the same Availability Zone.\n**C:** An Application Load Balancer (ALB) fronting an Auto Scaling Group (ASG) of EC2 instances in a single Availability Zone, storing data in an EC2 instance running a self-managed database software.\n**D:** Amazon API Gateway integrated with AWS Lambda functions for application logic, storing data in Amazon DynamoDB with global tables enabled.\n\n---\n\n**Correct Answer:** A\n\n**Explanation:**\n\n*   **A (Correct):**\n    *   **ALB:** Provides advanced routing features for HTTP/S traffic, handles load balancing, and offers high availability.\n    *   **ASG with EC2 instances (Multi-AZ & Spot/On-Demand):** Ensures automatic scalability (vertical and horizontal) to handle traffic spikes and maintains high availability across multiple Availability Zones. Using Spot Instances for stateless components is a prime cost-optimization strategy, while On-Demand can cover the baseline.\n    *   **RDS Multi-AZ:** Provides a fully managed, highly available database solution with automatic failover, meeting the database requirements. This pattern directly addresses all specified requirements for a typical 3-tier application migration.\n\n*   **B (Incorrect):**\n    *   **NLB:** While highly performant, it's typically used for TCP/UDP traffic or extreme performance HTTP/S, not ideal for a general web application with advanced routing needs.\n    *   **Single, large EC2 instance:** Fails on both high availability (single point of failure) and automatic scalability.\n    *   **Single-instance RDS in one AZ:** Fails on high availability for the database tier.\n\n*   **C (Incorrect):**\n    *   **ASG in a single Availability Zone:** Fails on high availability for the compute tier, as an AZ outage would bring down the application.\n    *   **EC2 instance running self-managed database:** Fails on the requirement for a *managed* database and typically lacks the built-in high availability and automated backups of RDS.\n\n*   **D (Incorrect):**\n    *   **API Gateway, Lambda, DynamoDB:** This is a highly scalable, highly available, and cost-effective serverless architecture. However, the question specifies migrating an \"existing 3-tier web application.\" While a re-architecture to serverless is possible, this option represents a significant re-platforming rather than an architectural pattern for migrating a traditional 3-tier application. It also doesn't explicitly mention \"web\" tier (e.g., serving static assets or client-side SPA), which a traditional 3-tier often implies beyond just API logic. For a direct migration scenario with minimal code changes, A is a more direct and commonly applied solution.\n\n---\n\n### Question 2: Terraform Script (Intermediate Level)\n\n**Question:** You need to provision several AWS SQS queues using Terraform. Each queue requires a unique name and a specific tag indicating its purpose. You have the following `locals` block defined:\n\n```terraform\nlocals {\n  queue_configs = {\n    \"order_processing\" = { name = \"order-queue\", purpose = \"Process new orders\" },\n    \"payment_updates\"  = { name = \"payment-update-queue\", purpose = \"Handle payment status changes\" },\n    \"notification_log\" = { name = \"notification-log-queue\", purpose = \"Log system notifications\" }\n  }\n}\n```\n\nWhich of the following Terraform `resource` blocks correctly creates an SQS queue for each entry in `local.queue_configs`, ensuring each queue has its unique name and a tag 'Purpose' set to its corresponding purpose?\n\n**A:**\n```terraform\nresource \"aws_sqs_queue\" \"app_queues\" {\n  for_each = local.queue_configs\n  name     = each.value.name\n  tags = {\n    Purpose = each.value.purpose\n  }\n}\n```\n\n**B:**\n```terraform\nresource \"aws_sqs_queue\" \"app_queues\" {\n  for_each = local.queue_configs\n  name     = each.key\n  tags = {\n    Purpose = each.value.purpose\n  }\n}\n```\n\n**C:**\n```terraform\nresource \"aws_sqs_queue\" \"app_queues\" {\n  count = length(local.queue_configs)\n  name  = local.queue_configs[count.index].name\n  tags = {\n    Purpose = local.queue_configs[count.index].purpose\n  }\n}\n```\n\n**D:**\n```terraform\nresource \"aws_sqs_queue\" \"app_queues\" {\n  count = length(local.queue_configs)\n  name  = each.value.name\n  tags = {\n    Purpose = each.value.purpose\n  }\n}\n```\n\n---\n\n**Correct Answer:** A\n\n**Explanation:**\n\n*   **A (Correct):**\n    *   `for_each = local.queue_configs`: This iterates over the keys and values of the `queue_configs` map. For each iteration, `each.key` will be the string key (e.g., \"order_processing\") and `each.value` will be the corresponding object (e.g., `{ name = \"order-queue\", purpose = \"Process new orders\" }`).\n    *   `name = each.value.name`: Correctly accesses the `name` attribute from the current `each.value` object.\n    *   `tags = { Purpose = each.value.purpose }`: Correctly sets the `Purpose` tag using the `purpose` attribute from the current `each.value` object. This is the idiomatic and correct way to provision multiple resources based on a map of configurations using `for_each`.\n\n*   **B (Incorrect):**\n    *   `name = each.key`: This would set the queue name to the map key (e.g., \"order_processing\") instead of the desired name from the inner object (\"order-queue\"). The requirement explicitly states \"unique name\" based on the `name` attribute in `queue_configs`.\n\n*   **C (Incorrect):**\n    *   `count = length(local.queue_configs)`: While `length()` can return the number of elements in a map, `count` relies on integer indices.\n    *   `local.queue_configs[count.index]`: Maps in Terraform (and Python, which Terraform expressions resemble) are not ordered by insertion and cannot be reliably indexed by integers (`count.index`). This expression would lead to an error or unpredictable behavior. `for_each` is designed for map-based iteration.\n\n*   **D (Incorrect):**\n    *   `count = length(local.queue_configs)`: As explained in C, `count` uses integer indices.\n    *   `name = each.value.name`: The `each` object (with `each.key` and `each.value`) is only available when using `for_each`, not with `count`. This would result in a syntax error.\n\n---\n\n### Question 3: Python Programming (Advanced Level)\n\n**Question:** You are tasked with creating a Python decorator `call_counter` that tracks the number of times *each* decorated function is called. The counter for a function should persist across multiple calls to that specific function, and each decorated function should maintain its own independent call count. The decorator should print the function's name and its current call count every time it's invoked.\n\nWhich of the following implementations correctly achieves this behavior without using external libraries, ensuring each function gets its own persistent counter?\n\n**A:**\n```python\ndef call_counter(func):\n    def wrapper(*args, **kwargs):\n        wrapper._call_count = getattr(wrapper, '_call_count', 0) + 1\n        print(f\"Function '{func.__name__}' called {wrapper._call_count} times.\")\n        return func(*args, **kwargs)\n    wrapper._call_count = 0\n    return wrapper\n```\n\n**B:**\n```python\ndef call_counter(func):\n    def wrapper(*args, **kwargs):\n        call_count = 0\n        call_count += 1\n        print(f\"Function '{func.__name__}' called {call_count} times.\")\n        return func(*args, **kwargs)\n    return wrapper\n```\n\n**C:**\n```python\ndef call_counter(func):\n    def wrapper(*args, **kwargs):\n        # This attempts to increment an attribute on the original function,\n        # but fails to handle its initial absence.\n        func._call_count += 1\n        print(f\"Function '{func.__name__}' called {func._call_count} times.\")\n        return func(*args, **kwargs)\n    return wrapper\n```\n\n**D:**\n```python\ndef call_counter(func):\n    def wrapper(*args, **kwargs):\n        # This will result in an UnboundLocalError for 'call_count'\n        nonlocal call_count\n        call_count = 0\n        call_count += 1\n        print(f\"Function '{func.__name__}' called {call_count} times.\")\n        return func(*args, **kwargs)\n    return wrapper\n```\n\n---\n\n**Correct Answer:** A\n\n**Explanation:**\n\n*   **A (Correct):**\n    *   This implementation attaches the `_call_count` attribute directly to the `wrapper` function object. Each time `call_counter` is applied to a new function, a *new* `wrapper` function is created, and thus a *new*, independent `_call_count` attribute is initialized on that specific `wrapper` instance.\n    *   `wrapper._call_count = getattr(wrapper, '_call_count', 0) + 1` ensures that if `_call_count` doesn't exist yet (on the very first call), it's initialized to 0 before incrementing, and subsequent calls correctly increment its persistent value.\n    *   `wrapper._call_count = 0` outside the inner `wrapper` function but within `call_counter` ensures that the attribute is initialized *once* when the decorator is applied, before any calls are made, avoiding issues with `getattr` needing to initialize on the first *call*. This makes the initialization explicit and robust.\n\n*   **B (Incorrect):**\n    *   `call_count = 0` is initialized *inside* the `wrapper` function. This means that `call_count` will be reset to `0` every single time the decorated function is called. It will always print \"Function '...' called 1 times.\" This fails to provide a persistent counter.\n\n*   **C (Incorrect):**\n    *   This attempts to increment an attribute `_call_count` directly on the original `func` object. While conceptually possible to use `getattr(func, '_call_count', 0) + 1` and then set it, the provided code `func._call_count += 1` will raise an `AttributeError` on the *first* call to the decorated function because `_call_count` has not been initialized on `func` yet. It lacks the safe initialization provided by `getattr` with a default value. Even if `func._call_count = 0` was placed in the outer `call_counter` scope, modifying the original `func` object directly can have unintended side effects, especially if `func` is later decorated by something else or used in contexts where the original object's state isn't expected to change. Attaching state to the `wrapper` closure is generally preferred.\n\n*   **D (Incorrect):**\n    *   The `nonlocal call_count` statement indicates that `call_count` refers to a variable in an enclosing scope. However, there is no `call_count` defined in the `call_counter`'s scope (or any other enclosing scope accessible by `nonlocal`). This will result in an `UnboundLocalError` when the `wrapper` function is defined and executed. If `call_count = 0` was moved to the `call_counter`'s scope, then `nonlocal call_count` inside `wrapper` *would* work for persistent counting, but as written, it's incorrect. Furthermore, even if `call_count` was correctly declared `nonlocal`, the line `call_count = 0` inside the `wrapper` would incorrectly reset the counter on every function call."
}
